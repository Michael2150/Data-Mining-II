{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Defects - 01 - Import & Clean\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import yaml\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from pprint import pprint \n",
    "\n",
    "DEBUG = True\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"jm1.csv\"\n",
    "\n",
    "import os, sys\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "ROOT = \"./\"\n",
    "\n",
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  if not os.path.isdir(\"/content/gdrive\"):\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    d = \"/content/gdrive/MyDrive/datasets\"\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d)\n",
    "  ROOT = f\"/content/gdrive/MyDrive/datasets/{DATASET.replace(' ','_')}/\"\n",
    "  if not os.path.isdir(ROOT): os.makedirs(ROOT)\n",
    "\n",
    "\n",
    "def makedirs(d):\n",
    "  if COLAB:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d)\n",
    "  else:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d, mode=0o777, exist_ok=True)\n",
    "\n",
    "for d in ['orig','data','output']: makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10878, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>DESIGN_COMPLEXITY</th>\n",
       "      <th>ESSENTIAL_COMPLEXITY</th>\n",
       "      <th>LOC_EXECUTABLE</th>\n",
       "      <th>HALSTEAD_CONTENT</th>\n",
       "      <th>HALSTEAD_DIFFICULTY</th>\n",
       "      <th>HALSTEAD_EFFORT</th>\n",
       "      <th>HALSTEAD_ERROR_EST</th>\n",
       "      <th>HALSTEAD_LENGTH</th>\n",
       "      <th>HALSTEAD_LEVEL</th>\n",
       "      <th>HALSTEAD_PROG_TIME</th>\n",
       "      <th>HALSTEAD_VOLUME</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>210.28</td>\n",
       "      <td>384.45</td>\n",
       "      <td>31079782.27</td>\n",
       "      <td>26.95</td>\n",
       "      <td>8441.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1726654.57</td>\n",
       "      <td>80843.08</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>202.98</td>\n",
       "      <td>213.53</td>\n",
       "      <td>9254819.86</td>\n",
       "      <td>14.45</td>\n",
       "      <td>4828.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>514156.64</td>\n",
       "      <td>43342.31</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>108.14</td>\n",
       "      <td>46.32</td>\n",
       "      <td>232043.52</td>\n",
       "      <td>1.67</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>12891.31</td>\n",
       "      <td>5009.32</td>\n",
       "      <td>295.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>206.01</td>\n",
       "      <td>4294926.45</td>\n",
       "      <td>6.95</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>238607.05</td>\n",
       "      <td>20848.47</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC_BLANK  BRANCH_COUNT  LOC_CODE_AND_COMMENT  LOC_COMMENTS  CYCLOMATIC_COMPLEXITY  DESIGN_COMPLEXITY  ESSENTIAL_COMPLEXITY  LOC_EXECUTABLE  HALSTEAD_CONTENT  HALSTEAD_DIFFICULTY  HALSTEAD_EFFORT  HALSTEAD_ERROR_EST  HALSTEAD_LENGTH  HALSTEAD_LEVEL  HALSTEAD_PROG_TIME  HALSTEAD_VOLUME  NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  LOC_TOTAL  label\n",
       "0      447.0         826.0                  12.0         157.0                  470.0              385.0                 113.0          2824.0            210.28               384.45      31079782.27               26.95           8441.0            0.00          1726654.57         80843.08        3021.0         5420.0                609.0                 155.0     3442.0      1\n",
       "1        0.0         211.0                   0.0           0.0                  128.0              104.0                  14.0             0.0              0.00                 0.00             0.00                0.00              0.0            0.00                0.00             0.00           0.0            0.0                  0.0                   0.0     1129.0      1\n",
       "2      164.0         485.0                  10.0          58.0                  268.0              219.0                  39.0          1588.0            202.98               213.53       9254819.86               14.45           4828.0            0.00           514156.64         43342.31        1730.0         3172.0                407.0                 102.0     1824.0      1\n",
       "3       37.0          29.0                   8.0          42.0                   19.0               19.0                   6.0           133.0            108.14                46.32        232043.52                1.67            685.0            0.02            12891.31          5009.32         295.0          390.0                121.0                  38.0      222.0      1\n",
       "4       11.0         405.0                   0.0          17.0                  404.0                2.0                   1.0           814.0            101.20               206.01       4294926.45                6.95           2033.0            0.00           238607.05         20848.47         813.0         1220.0                811.0                 411.0      844.0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ROOT+\"orig/\"+DATASET)\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Values\n",
    "\n",
    "### Null Value Checks\n",
    "\n",
    "Here we can see that there are no apparent null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC_BLANK                0\n",
       "BRANCH_COUNT             0\n",
       "LOC_CODE_AND_COMMENT     0\n",
       "LOC_COMMENTS             0\n",
       "CYCLOMATIC_COMPLEXITY    0\n",
       "DESIGN_COMPLEXITY        0\n",
       "ESSENTIAL_COMPLEXITY     0\n",
       "LOC_EXECUTABLE           0\n",
       "HALSTEAD_CONTENT         0\n",
       "HALSTEAD_DIFFICULTY      0\n",
       "HALSTEAD_EFFORT          0\n",
       "HALSTEAD_ERROR_EST       0\n",
       "HALSTEAD_LENGTH          0\n",
       "HALSTEAD_LEVEL           0\n",
       "HALSTEAD_PROG_TIME       0\n",
       "HALSTEAD_VOLUME          0\n",
       "NUM_OPERANDS             0\n",
       "NUM_OPERATORS            0\n",
       "NUM_UNIQUE_OPERANDS      0\n",
       "NUM_UNIQUE_OPERATORS     0\n",
       "LOC_TOTAL                0\n",
       "label                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Cases & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 'label'\n",
      "Cases: 10878\n",
      "Features: 21\n"
     ]
    }
   ],
   "source": [
    "target = \"label\"\n",
    "features = list(df.columns)\n",
    "features.remove(target)\n",
    "counts_features = [col for col in df.columns if \"COUNT\" in col or \"LOC\" in col or \"NUM\" in col]\n",
    "\n",
    "print(f\"Target: '{target}'\")\n",
    "print(f\"Cases: {len(df)}\")\n",
    "print(f\"Features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implausible Value Checks\n",
    "\n",
    "Note:\n",
    "1. `LOC_TOTAL` is never = 0\n",
    "2. values are always positive ie >=0\n",
    "3. count values are always integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 1 is True\n"
     ]
    }
   ],
   "source": [
    "# Check that `LOC_TOTAL` is always positive and non-zero\n",
    "check_1 = df[df[\"LOC_TOTAL\"] <= 0]\n",
    "print(f\"Check 1 is {check_1.shape[0] == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 2 is True\n"
     ]
    }
   ],
   "source": [
    "# Check that all columns are positive or zero\n",
    "check_2 = True\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [np.float64, np.int64]:\n",
    "        filter = df[col] < 0\n",
    "        check_2 = check_2 and (len(df[filter]) == 0)\n",
    "print(f\"Check 2 is {check_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 3 is True\n"
     ]
    }
   ],
   "source": [
    "# Check that all count features are integers\n",
    "check_3 = True\n",
    "for col in counts_features:\n",
    "    filter = (df[col] % 1 != 0)\n",
    "    check_3 = check_3 and (len(df[filter]) == 0)\n",
    "print(f\"Check 3 is {check_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a value is implausible for a given feature\n",
    "def is_implausible(case_value, feature_name):\n",
    "    if feature_name == \"LOC_TOTAL\":\n",
    "        return case_value <= 0\n",
    "    if feature_name in counts_features:\n",
    "        return case_value % 1 != 0 or case_value < 0\n",
    "    return case_value < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data quality\n",
    "\n",
    "### A - Identical features\n",
    "\n",
    "Refers to a situation where two or more features contain identical values for all cases.\n",
    "\n",
    "F1=F2=F3 ∧ F4=F5 =⇒ 3 features are identical so could be deleted.\n",
    "\n",
    "Expected output: 0\n",
    " \n",
    "Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical columns: 0\n"
     ]
    }
   ],
   "source": [
    "identical_column_count = 0\n",
    "cols = df.columns\n",
    "for i in range(len(cols)-2): # Go through colums 0 to n-2\n",
    "    for j in range(i+1, len(cols)-1): # Go through columns 1 to n-1\n",
    "        for k in range(j+1, len(cols)): # Go through columns 2 to n\n",
    "            if df[cols[i]].equals(df[cols[j]]) and df[cols[j]].equals(df[cols[k]]):\n",
    "                print(f\"Columns {cols[i]}, {cols[j]} and {cols[k]} are identical\")\n",
    "                identical_column_count += 1\n",
    "\n",
    "print(f\"Identical columns: {identical_column_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Constant features\n",
    "\n",
    "Refers to features that contain the same value for every instance, i.e. add no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the same value for all rows: 0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        print(f\"Column {col} has the same value for all rows\")\n",
    "        count += 1\n",
    "\n",
    "print(f\"Columns with the same value for all rows: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - Features with missing values\n",
    "\n",
    "Counts the number of features that contain one or more missing observations\n",
    "\n",
    "F1 has 10 missing values ∧ F3 has 3 missing values =⇒ 2 features contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "total_missing = df.isnull().sum().sum()\n",
    "for col in df.columns:\n",
    "    missing_vals = df[col].isnull().sum()\n",
    "    if missing_vals > 0:\n",
    "        print(f\"Column {col} has {missing_vals} missing values\")\n",
    "\n",
    "print(f\"Total missing values: {total_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D - Features with conflicting values\n",
    "\n",
    "Counts features that violate some referential integrity constraint\n",
    "\n",
    "F1 should equal F2+F3 but does not. We cannot say which feature is in error therefore =⇒ 3 problematic features.\n",
    "\n",
    "According to the document the following features should be equal:\n",
    "\n",
    "10. `HALSTEAD_LENGTH` = `NUM_OPERATORS` + `NUM_OPERANDS` \n",
    "    \n",
    "13) `HALSTEAD_VOLUME` = (`NUM_OPERATORS` + `NUM_OPERANDS`) * log2(`NUM_UNIQUE_OPERATORS` + `NUM_UNIQUE_OPERANDS`)\n",
    "14) `HALSTEAD_LEVEL` = (2 / `NUM_UNIQUE_OPERATORS`) * (`NUM_UNIQUE_OPERANDS` / `NUM_OPERANDS`)\n",
    "15)  `HALSTEAD_DIFFICULTY` = (`NUM_UNIQUE_OPERATORS` / 2) * (`NUM_OPERANDS` / `NUM_UNIQUE_OPERANDS`)\n",
    "16)  `HALSTEAD_CONTENT` = `HALSTEAD_VOLUME` / `HALSTEAD_DIFFICULTY`\n",
    "17)  `HALSTEAD_EFFORT` = `HALSTEAD_VOLUME` * `HALSTEAD_DIFFICULTY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with integrity check failure: 139 (139 new)\n",
      "Rows with integrity check failure: 4964 (4825 new)\n",
      "Rows with integrity check failure: 9744 (5568 new)\n",
      "Rows with integrity check failure: 6595 (79 new)\n",
      "Rows with integrity check failure: 9854 (82 new)\n",
      "Rows with integrity check failure: 6986 (2 new)\n",
      "Total rows with integrity check failure: 10695\n"
     ]
    }
   ],
   "source": [
    "def get_integrity_check_filters(df):\n",
    "    return [\n",
    "        # `HALSTEAD_LENGTH` = `NUM_OPERATORS` + `NUM_OPERANDS` \n",
    "        np.isclose(df[\"HALSTEAD_LENGTH\"], df[\"NUM_OPERATORS\"] + df[\"NUM_OPERANDS\"]),\n",
    "        \n",
    "        # `HALSTEAD_VOLUME` = (`NUM_OPERATORS` + `NUM_OPERANDS`) * log2(`NUM_UNIQUE_OPERATORS` + `NUM_UNIQUE_OPERANDS`)\n",
    "        np.isclose(df[\"HALSTEAD_VOLUME\"], ((df[\"NUM_OPERATORS\"] + df[\"NUM_OPERANDS\"]) * np.log2(df[\"NUM_UNIQUE_OPERATORS\"] + df[\"NUM_UNIQUE_OPERANDS\"]))),\n",
    "        \n",
    "        # `HALSTEAD_LEVEL` = (2 / `NUM_UNIQUE_OPERATORS`) * (`NUM_UNIQUE_OPERANDS` / `NUM_OPERANDS`)\n",
    "        np.isclose(df[\"HALSTEAD_LEVEL\"], ((2 / df[\"NUM_UNIQUE_OPERATORS\"]) * (df[\"NUM_UNIQUE_OPERANDS\"] / df[\"NUM_OPERANDS\"]))),\n",
    "        \n",
    "        # `HALSTEAD_DIFFICULTY` = (`NUM_UNIQUE_OPERATORS` / 2) * (`NUM_OPERANDS` / `NUM_UNIQUE_OPERANDS`)\n",
    "        np.isclose(df[\"HALSTEAD_DIFFICULTY\"], ((df[\"NUM_UNIQUE_OPERATORS\"] / 2) * (df[\"NUM_OPERANDS\"] / df[\"NUM_UNIQUE_OPERANDS\"]))),\n",
    "        \n",
    "        # `HALSTEAD_CONTENT` = `HALSTEAD_VOLUME` / `HALSTEAD_DIFFICULTY`\n",
    "        np.isclose(df[\"HALSTEAD_CONTENT\"], (df[\"HALSTEAD_VOLUME\"] / df[\"HALSTEAD_DIFFICULTY\"])),\n",
    "        \n",
    "        # `HALSTEAD_EFFORT` = `HALSTEAD_VOLUME` * `HALSTEAD_DIFFICULTY`\n",
    "        np.isclose(df[\"HALSTEAD_EFFORT\"], (df[\"HALSTEAD_VOLUME\"] * df[\"HALSTEAD_DIFFICULTY\"])),\n",
    "    ]\n",
    "\n",
    "filters = get_integrity_check_filters(df)\n",
    "\n",
    "failure_rows = set()\n",
    "\n",
    "for filter in filters:\n",
    "    df_filtered = df[~filter]\n",
    "    row_count = len(df_filtered)\n",
    "    new_rows_count = 0\n",
    "    for index in df_filtered.index:\n",
    "        if index not in failure_rows:\n",
    "            new_rows_count += 1\n",
    "    failure_rows = failure_rows.union(set(df_filtered.index))\n",
    "    print(f\"Rows with integrity check failure: {row_count} ({new_rows_count} new)\")\n",
    "\n",
    "print(f\"Total rows with integrity check failure: {len(failure_rows)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E - Features with implausible values\n",
    "\n",
    "Counts features that violate some integrity constraint\n",
    "\n",
    "F1 should be non-negative but contains 1 or more instances < 0 =⇒ 1 problematic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total implausible values: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_quality_E(df):\n",
    "    implausible_values = {}\n",
    "    for col in df.columns:\n",
    "        implausible_values[col] = df[df[col].apply(lambda x: is_implausible(x, col))]\n",
    "    \n",
    "    total_implausible = sum([len(implausible_values[col]) for col in implausible_values])\n",
    "    print(f\"Total implausible values: {total_implausible}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "filter_quality_E(df.copy())\n",
    "print() # to stop the output from the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F - Total problem features\n",
    "\n",
    "Count of features impacted by 1 or more of A-E. Since features may contain more than one problem this need not be the sum of A to E ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_quality_F(df):\n",
    "    print(\"Removing rows with missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G - Identical Cases\n",
    "\n",
    "Refers to a situation where two or more cases contain identical values for all features including class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_G = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H - Inconsistent cases\n",
    "\n",
    "As per G but the class labels differ, all other data item values are identical\n",
    "\n",
    "There are two identical modules M1 and M2 where M1 is labelled as fault free and M2 is labelled as faulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_H = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Cases with missing values\n",
    "\n",
    "Counts the number of cases that contain one or more missing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_I = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J - Cases with conflicting feature values\n",
    "\n",
    "Counts cases that contain features (2 or more by definition) that violate some referential integrity constraint. Count each case irrespective of the number of features implicated\n",
    "\n",
    "As per Column D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 7636\n"
     ]
    }
   ],
   "source": [
    "def filter_quality_J(df, filters):\n",
    "    indeces = set()\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        row_index, row_data = row\n",
    "        for filter in filters:\n",
    "            if not filter[row_index]:\n",
    "                indeces.add(row_index)\n",
    "\n",
    "    return df.drop(indeces)\n",
    "\n",
    "filters = get_integrity_check_filters(df, atol=1e-08, rtol=0.01)\n",
    "filtered_df = filter_quality_J(df.copy(), filters)\n",
    "print(f\"Rows removed: {len(df) - len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Cases with implausible values\n",
    "\n",
    "Counts cases that violate some integrity constraint. Count each case irrespective of the number of features implicated.\n",
    "\n",
    "As per Column E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_K = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 10878 x 21\n"
     ]
    }
   ],
   "source": [
    "def preprocess(ds):\n",
    "    # Pull out the target feature\n",
    "    target_feature = ds.iloc[:, -1]\n",
    "    # Drop the target feature from the dataset\n",
    "    ds = ds.iloc[:, :-1]\n",
    "\n",
    "    data = None\n",
    "    M = ds.shape[0]\n",
    "    N = ds.shape[1] \n",
    "    print(f\"Dataset shape: {M} x {N}\")\n",
    "\n",
    "    # step 1: remove cases with implausible values\n",
    "    # Not Required as the dataset has no implausible values as per the checks above\n",
    "    \n",
    "    # step 2: remove cases with conflict feature values\n",
    "    \n",
    "\n",
    "    # step 3: remove identical cases\n",
    "    \n",
    "\n",
    "    # step 4: remove inconsistent cases\n",
    "                \n",
    "    # step 5: remove cases with missing values\n",
    "                \n",
    "    # step 6: remove constant features\n",
    "                \n",
    "    # step 7: remove identical features\n",
    "    \n",
    "\n",
    "preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L - Total of data quality problem cases\n",
    "\n",
    "Count of cases impacted by one or more of I to K that we denote DS0. Since cases may contain more than one problem this need not be the sum of I to K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_L = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M - Total problem cases according to [6]\n",
    "\n",
    "Count of cases impacted by one or more of G to K denoted DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_M = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
